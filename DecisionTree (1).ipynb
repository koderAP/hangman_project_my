{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "amlkrWzYC7Un"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import requests\n",
        "import random\n",
        "import string\n",
        "import secrets\n",
        "import time\n",
        "import collections\n",
        "import re\n",
        "from urllib.parse import parse_qs\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.feature_extraction import DictVectorizer\n",
        "from collections import defaultdict\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "import random\n",
        "from collections import defaultdict\n",
        "from sklearn.feature_extraction import DictVectorizer\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "\n",
        "try:\n",
        "    from urllib.parse import parse_qs, urlencode, urlparse\n",
        "except ImportError:\n",
        "    from urlparse import parse_qs, urlparse\n",
        "    from urllib import urlencode\n",
        "\n",
        "from requests.packages.urllib3.exceptions import InsecureRequestWarning\n",
        "\n",
        "requests.packages.urllib3.disable_warnings(InsecureRequestWarning)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "LUljDrQhDQ23"
      },
      "outputs": [],
      "source": [
        "file_path = 'words_250000_train.txt'\n",
        "with open(file_path, 'r', encoding='utf-8') as file:\n",
        "    content = file.read()\n",
        "words = content.split('\\n')  # Replace with your words"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "DElSvz2uhH6Z"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "\n",
        "def randomly_mask_string(input_string, mask_probability):\n",
        "    masked_string = \"\"\n",
        "    for char in input_string:\n",
        "        if random.random() < mask_probability:\n",
        "            masked_string += \"_\"\n",
        "        else:\n",
        "            masked_string += char\n",
        "    return masked_string\n",
        "\n",
        "mask_probability = 0.6\n",
        "\n",
        "tr1 = []\n",
        "\n",
        "for i in range(len(words)):\n",
        "        num_replacements = 1\n",
        "        tr1.append(randomly_mask_string(words[i],mask_probability))\n",
        "\n",
        "mask_probability = 0.5\n",
        "\n",
        "tr11 = []\n",
        "\n",
        "for i in range(len(words)):\n",
        "        num_replacements = 1\n",
        "        tr11.append(randomly_mask_string(words[i],mask_probability))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "z3ODKoG1sP5C"
      },
      "outputs": [],
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "3wTeDCYTmMNM"
      },
      "outputs": [],
      "source": [
        "tr2 = []\n",
        "\n",
        "def next_guess(masked,full):\n",
        "    for i in range(len(masked)):\n",
        "        if masked[i]==\"_\":\n",
        "            return full[i]\n",
        "    return \"\"\n",
        "for i in range(len(words)):\n",
        "    tr2.append((tr1[i],next_guess(tr1[i],words[i])))\n",
        "    tr2.append((tr11[i],next_guess(tr11[i],words[i])))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "TzL6T_r5shut"
      },
      "outputs": [],
      "source": [
        "mask_probability = 0.6\n",
        "\n",
        "tr1 = []\n",
        "\n",
        "for i in range(len(words)):\n",
        "        num_replacements = 1\n",
        "        tr1.append(randomly_mask_string(words[i],mask_probability))\n",
        "\n",
        "mask_probability = 0.5\n",
        "\n",
        "tr11 = []\n",
        "\n",
        "for i in range(len(words)):\n",
        "        num_replacements = 1\n",
        "        tr11.append(randomly_mask_string(words[i],mask_probability))\n",
        "\n",
        "for i in range(len(words)):\n",
        "    tr2.append((tr1[i],next_guess(tr1[i],words[i])))\n",
        "    tr2.append((tr11[i],next_guess(tr11[i],words[i])))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mask_probability = 0.6\n",
        "\n",
        "tr1 = []\n",
        "\n",
        "for i in range(len(words)):\n",
        "        num_replacements = 1\n",
        "        tr1.append(randomly_mask_string(words[i],mask_probability))\n",
        "\n",
        "mask_probability = 0.6\n",
        "\n",
        "tr11 = []\n",
        "\n",
        "for i in range(len(words)):\n",
        "        num_replacements = 1\n",
        "        tr11.append(randomly_mask_string(words[i],mask_probability))\n",
        "\n",
        "for i in range(len(words)):\n",
        "    tr2.append((tr1[i],next_guess(tr1[i],words[i])))\n",
        "    tr2.append((tr11[i],next_guess(tr11[i],words[i])))"
      ],
      "metadata": {
        "id": "FIGQ_E69maHl"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NaVQTnUdhzMJ",
        "outputId": "0a302701-02a7-4bd9-9075-e64f7670c3a0"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('__l_____', 'a'),\n",
              " ('aa___u__', 'l'),\n",
              " ('aa__i_', 'l'),\n",
              " ('_a___s', 'a'),\n",
              " ('aa_s_', 'l'),\n",
              " ('__lst', 'a'),\n",
              " ('___', 'a'),\n",
              " ('_a_', 'a'),\n",
              " ('___dahl', 'a'),\n",
              " ('aa__ahl', 'n')]"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "source": [
        "tr2[:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "45OwDB8OjF6x"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3tEXHiOaDlo0",
        "outputId": "b2d74d62-88cb-4dc6-95a3-20dd255017f3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "List of Substrings Sorted by Frequency:\n",
            "['e', 's', 'i', 'a', 'r', 'n', 't', 'o', 'l', 'c', 'd', 'u', 'g', 'p', 'm', 'h', 'b', 'y', 'f', 'v', 'k', 'w', 'z', 'x', 'j', 'q']\n"
          ]
        }
      ],
      "source": [
        "from collections import defaultdict\n",
        "\n",
        "\n",
        "def analyze_all_substring_frequencies(dictionary, substring_length):\n",
        "    substring_frequencies = defaultdict(int)\n",
        "\n",
        "    for word in dictionary:\n",
        "        for i in range(len(word) - substring_length + 1):\n",
        "            substring = word[i:i+substring_length]\n",
        "            substring_frequencies[substring] += 1\n",
        "\n",
        "\n",
        "    sorted_substring_frequencies = dict(sorted(substring_frequencies.items(), key=lambda item: item[1], reverse=True))\n",
        "\n",
        "    return sorted_substring_frequencies\n",
        "\n",
        "\n",
        "substring_length = 1\n",
        "substring_frequencies = analyze_all_substring_frequencies(words, substring_length)\n",
        "\n",
        "\n",
        "sorted_keys_by_frequency = sorted(substring_frequencies, key=substring_frequencies.get, reverse=True)\n",
        "\n",
        "sorted_keys_by_frequency = ['e','s','i','a','r','n','t','o','l','c','d','u','g','p','m','h','b','y','f','v','k', 'w', 'z', 'x', 'j','q']\n",
        "print(f\"List of Substrings Sorted by Frequency:\")\n",
        "print(sorted_keys_by_frequency)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "NQKRVzgrDlYe"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "NRe2pTUqWYWs"
      },
      "outputs": [],
      "source": [
        "class HangmanAPI(object):\n",
        "    def __init__(self, access_token=None, session=None, timeout=None):\n",
        "        self.hangman_url = self.determine_hangman_url()\n",
        "        self.access_token = access_token\n",
        "        self.session = session or requests.Session()\n",
        "        self.timeout = timeout\n",
        "        self.guessed_letters = []\n",
        "\n",
        "        full_dictionary_location = \"words_250000_train.txt\"\n",
        "        self.full_dictionary = self.build_dictionary(full_dictionary_location)\n",
        "        self.full_dictionary_common_letter_sorted = sorted_keys_by_frequency\n",
        "\n",
        "        self.current_dictionary = []\n",
        "        self.vectorizer = DictVectorizer()\n",
        "        self.model = DecisionTreeClassifier()\n",
        "        self.train_ml_model()\n",
        "\n",
        "    @staticmethod\n",
        "    def determine_hangman_url():\n",
        "        links = ['https://trexsim.com', 'https://sg.trexsim.com']\n",
        "\n",
        "        data = {link: 0 for link in links}\n",
        "\n",
        "        for link in links:\n",
        "\n",
        "            requests.get(link)\n",
        "\n",
        "            for i in range(10):\n",
        "                s = time.time()\n",
        "                requests.get(link)\n",
        "                data[link] = time.time() - s\n",
        "\n",
        "        link = sorted(data.items(), key=lambda x: x[1])[0][0]\n",
        "        link += '/trexsim/hangman'\n",
        "        return link\n",
        "\n",
        "\n",
        "    def train_ml_model(self):\n",
        "        training_data = tr2\n",
        "        X_train = []\n",
        "        y_train = []\n",
        "\n",
        "        for masked_word, guessed_letter in training_data:\n",
        "            revealed_letters = [letter for letter in masked_word if letter != \"_\"]\n",
        "            features = self.generate_features(revealed_letters, guessed_letter)\n",
        "            X_train.append(features)\n",
        "            y_train.append(guessed_letter)\n",
        "\n",
        "        self.vectorizer = DictVectorizer()\n",
        "        X_train_vectorized = self.vectorizer.fit_transform(X_train)\n",
        "\n",
        "        self.model = DecisionTreeClassifier()\n",
        "        self.model.fit(X_train_vectorized, y_train)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    def guess_ngram_based(self, revealed_letters, word, ngram_size):\n",
        "        ngrams = self.generate_ngrams(self.current_dictionary, ngram_size)\n",
        "        filtered_ngrams = {\n",
        "            ngram: frequency for ngram, frequency in ngrams.items()\n",
        "            if any(letter in ngram for letter in revealed_letters)\n",
        "        }\n",
        "\n",
        "        if not filtered_ngrams:\n",
        "            return self.guess_default()\n",
        "\n",
        "        max_frequency_ngram = max(filtered_ngrams, key=filtered_ngrams.get)\n",
        "        available_letters = [letter for letter in max_frequency_ngram if letter not in self.guessed_letters]\n",
        "\n",
        "        if available_letters:\n",
        "            self.guessed_letters.append(available_letters[0])\n",
        "            return available_letters[0]\n",
        "\n",
        "        return self.guess_default()\n",
        "\n",
        "    def guess_ml_based(self, revealed_letters, word, top_n=4):\n",
        "        print(\"///////////////////////////////////////\")\n",
        "        X = self.generate_features(revealed_letters, word)\n",
        "        X_vectorized = self.vectorizer.transform(X)\n",
        "\n",
        "        predicted_probabilities = self.model.predict_proba(X_vectorized)\n",
        "\n",
        "        available_probabilities = []\n",
        "        for i, letter in enumerate(self.full_dictionary_common_letter_sorted):\n",
        "            if letter not in self.guessed_letters:\n",
        "                available_probabilities.append((i, predicted_probabilities[0][i]))\n",
        "\n",
        "        if available_probabilities:\n",
        "            available_probabilities.sort(key=lambda x: x[1], reverse=True)\n",
        "            top_available_indices = [index for index, _ in available_probabilities[:top_n]]\n",
        "\n",
        "\n",
        "            if all(self.full_dictionary_common_letter_sorted[index] in self.guessed_letters for index in top_available_indices):\n",
        "                return self.guess_ngram_based(revealed_letters, word,4)\n",
        "\n",
        "\n",
        "            for index in top_available_indices:\n",
        "                letter = self.full_dictionary_common_letter_sorted[index]\n",
        "                if letter not in self.guessed_letters:\n",
        "                    self.guessed_letters.append(letter)\n",
        "                    return letter\n",
        "\n",
        "        return self.guess_default()\n",
        "\n",
        "    def generate_ngrams(self, dictionary, n):\n",
        "        print(\"n gram chal gya\")\n",
        "        ngram_frequencies = defaultdict(int)\n",
        "        for word in dictionary:\n",
        "            for i in range(len(word) - n + 1):\n",
        "                ngram = word[i:i + n]\n",
        "                ngram_frequencies[ngram] += 1\n",
        "\n",
        "        sorted_ngram_frequencies = dict(sorted(ngram_frequencies.items(), key=lambda item: item[1], reverse=True))\n",
        "        return sorted_ngram_frequencies\n",
        "\n",
        "\n",
        "    def guess(self, word):\n",
        "        s = ''\n",
        "        for i in word:\n",
        "          if i!=\" \":\n",
        "            s+=i\n",
        "        word = s\n",
        "        c = 0\n",
        "        for i in word:\n",
        "            if i == \"_\":\n",
        "                c+=1\n",
        "        ngram_size = 2\n",
        "        print(word,len(word))\n",
        "        if c==len(word):\n",
        "            return self.guess_default()\n",
        "\n",
        "        if word[-2:]==\"l_\":\n",
        "            if 'y' not in self.guessed_letters:\n",
        "                self.guessed_letters.append('y')\n",
        "                return 'y'\n",
        "\n",
        "        if len(word)>5:\n",
        "            if word[-3:]==\"in_\":\n",
        "                if 'g' not in self.guessed_letters:\n",
        "                    self.guessed_letters.append('g')\n",
        "                    return 'g'\n",
        "\n",
        "        revealed_letters = [letter for letter in word if letter != \"_\"]\n",
        "        if len(word)<5:\n",
        "            return self.guess_ngram_based(revealed_letters, word, ngram_size)\n",
        "        if revealed_letters:\n",
        "            return self.guess_ml_based(revealed_letters, word)\n",
        "\n",
        "\n",
        "    def generate_features(self, revealed_letters, word):\n",
        "        feature = {'letter': None}\n",
        "        for letter in self.full_dictionary_common_letter_sorted:\n",
        "            if letter not in self.guessed_letters:\n",
        "                feature['letter'] = letter\n",
        "                for revealed_letter in revealed_letters:\n",
        "                    feature[f'prev_{revealed_letter}'] = int(revealed_letter in word)  # Use binary encoding\n",
        "                #break  # Stop after finding the first unguessed letter\n",
        "        return feature\n",
        "\n",
        "\n",
        "    ##########################################################\n",
        "    # You'll likely not need to modify any of the code below #\n",
        "    ##########################################################\n",
        "    def guess_default(self):\n",
        "        print(\"bola tha na\")\n",
        "        for i in self.full_dictionary_common_letter_sorted:\n",
        "            if i not in self.guessed_letters:\n",
        "                self.guessed_letters.append(i)\n",
        "                return i\n",
        "\n",
        "        return \" \"\n",
        "\n",
        "\n",
        "\n",
        "    def build_dictionary(self, dictionary_file_location):\n",
        "        text_file = open(dictionary_file_location,\"r\")\n",
        "        full_dictionary = text_file.read().splitlines()\n",
        "        text_file.close()\n",
        "        return full_dictionary\n",
        "\n",
        "    def start_game(self, practice=True, verbose=True):\n",
        "        # reset guessed letters to empty set and current plausible dictionary to the full dictionary\n",
        "        self.guessed_letters = []\n",
        "        self.current_dictionary = self.full_dictionary\n",
        "\n",
        "        response = self.request(\"/new_game\", {\"practice\":practice})\n",
        "        if response.get('status')==\"approved\":\n",
        "            game_id = response.get('game_id')\n",
        "            word = response.get('word')\n",
        "            tries_remains = response.get('tries_remains')\n",
        "            if verbose:\n",
        "                print(\"Successfully start a new game! Game ID: {0}. # of tries remaining: {1}. Word: {2}.\".format(game_id, tries_remains, word))\n",
        "            while tries_remains>0:\n",
        "                # get guessed letter from user code\n",
        "                guess_letter = self.guess(word)\n",
        "\n",
        "                # append guessed letter to guessed letters field in hangman object\n",
        "                self.guessed_letters.append(guess_letter)\n",
        "                if verbose:\n",
        "                    print(\"Guessing letter: {0}\".format(guess_letter))\n",
        "\n",
        "                try:\n",
        "                    res = self.request(\"/guess_letter\", {\"request\":\"guess_letter\", \"game_id\":game_id, \"letter\":guess_letter})\n",
        "                except HangmanAPIError:\n",
        "                    print('HangmanAPIError exception caught on request.')\n",
        "                    continue\n",
        "                except Exception as e:\n",
        "                    print('Other exception caught on request.')\n",
        "                    raise e\n",
        "\n",
        "                if verbose:\n",
        "                    print(\"Sever response: {0}\".format(res))\n",
        "                status = res.get('status')\n",
        "                tries_remains = res.get('tries_remains')\n",
        "                if status==\"success\":\n",
        "                    if verbose:\n",
        "                        print(\"Successfully finished game: {0}\".format(game_id))\n",
        "                    return True\n",
        "                elif status==\"failed\":\n",
        "                    reason = res.get('reason', '# of tries exceeded!')\n",
        "                    if verbose:\n",
        "                        print(\"Failed game: {0}. Because of: {1}\".format(game_id, reason))\n",
        "                    return False\n",
        "                elif status==\"ongoing\":\n",
        "                    word = res.get('word')\n",
        "        else:\n",
        "            if verbose:\n",
        "                print(\"Failed to start a new game\")\n",
        "        return status==\"success\"\n",
        "\n",
        "    def my_status(self):\n",
        "        return self.request(\"/my_status\", {})\n",
        "\n",
        "    def request(\n",
        "            self, path, args=None, post_args=None, method=None):\n",
        "        if args is None:\n",
        "            args = dict()\n",
        "        if post_args is not None:\n",
        "            method = \"POST\"\n",
        "\n",
        "        # Add `access_token` to post_args or args if it has not already been\n",
        "        # included.\n",
        "        if self.access_token:\n",
        "            # If post_args exists, we assume that args either does not exists\n",
        "            # or it does not need `access_token`.\n",
        "            if post_args and \"access_token\" not in post_args:\n",
        "                post_args[\"access_token\"] = self.access_token\n",
        "            elif \"access_token\" not in args:\n",
        "                args[\"access_token\"] = self.access_token\n",
        "\n",
        "        time.sleep(0.2)\n",
        "\n",
        "        num_retry, time_sleep = 50, 2\n",
        "        for it in range(num_retry):\n",
        "            try:\n",
        "                response = self.session.request(\n",
        "                    method or \"GET\",\n",
        "                    self.hangman_url + path,\n",
        "                    timeout=self.timeout,\n",
        "                    params=args,\n",
        "                    data=post_args,\n",
        "                    verify=False\n",
        "                )\n",
        "                break\n",
        "            except requests.HTTPError as e:\n",
        "                response = json.loads(e.read())\n",
        "                raise HangmanAPIError(response)\n",
        "            except requests.exceptions.SSLError as e:\n",
        "                if it + 1 == num_retry:\n",
        "                    raise\n",
        "                time.sleep(time_sleep)\n",
        "\n",
        "        headers = response.headers\n",
        "        if 'json' in headers['content-type']:\n",
        "            result = response.json()\n",
        "        elif \"access_token\" in parse_qs(response.text):\n",
        "            query_str = parse_qs(response.text)\n",
        "            if \"access_token\" in query_str:\n",
        "                result = {\"access_token\": query_str[\"access_token\"][0]}\n",
        "                if \"expires\" in query_str:\n",
        "                    result[\"expires\"] = query_str[\"expires\"][0]\n",
        "            else:\n",
        "                raise HangmanAPIError(response.json())\n",
        "        else:\n",
        "            raise HangmanAPIError('Maintype was not text, or querystring')\n",
        "\n",
        "        if result and isinstance(result, dict) and result.get(\"error\"):\n",
        "            raise HangmanAPIError(result)\n",
        "        return result\n",
        "\n",
        "class HangmanAPIError(Exception):\n",
        "    def __init__(self, result):\n",
        "        self.result = result\n",
        "        self.code = None\n",
        "        try:\n",
        "            self.type = result[\"error_code\"]\n",
        "        except (KeyError, TypeError):\n",
        "            self.type = \"\"\n",
        "\n",
        "        try:\n",
        "            self.message = result[\"error_description\"]\n",
        "        except (KeyError, TypeError):\n",
        "            try:\n",
        "                self.message = result[\"error\"][\"message\"]\n",
        "                self.code = result[\"error\"].get(\"code\")\n",
        "                if not self.type:\n",
        "                    self.type = result[\"error\"].get(\"type\", \"\")\n",
        "            except (KeyError, TypeError):\n",
        "                try:\n",
        "                    self.message = result[\"error_msg\"]\n",
        "                except (KeyError, TypeError):\n",
        "                    self.message = result\n",
        "\n",
        "        Exception.__init__(self, self.message)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "6IOiArnSHoC-"
      },
      "outputs": [],
      "source": [
        "api = HangmanAPI(access_token=\"dfcf6b9bfe4669669dbf9ec1c3775d\", timeout=2000)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lSadtonMBfai",
        "outputId": "cc9b75dd-471a-40fe-8700-481f84c5bc04"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[7832, 1, 0, 976]\n"
          ]
        }
      ],
      "source": [
        "l= api.my_status()\n",
        "\n",
        "#[total_practice_runs,total_recorded_runs,total_recorded_successes,total_practice_successes]\n",
        "\n",
        "print(l)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SfG0OHORC3Ff"
      },
      "outputs": [],
      "source": [
        "for i in range(1000):\n",
        "    print('Playing ', i, ' th game')\n",
        "    # Uncomment the following line to execute your final runs. Do not do this until you are satisfied with your submission\n",
        "    api.start_game(practice=0,verbose=False)\n",
        "\n",
        "    # DO NOT REMOVE as otherwise the server may lock you out for too high frequency of requests\n",
        "    time.sleep(0.5)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "6PdluduoC7Kc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2a6e45e0-7a19-4b6b-f58f-e8dca38f9018"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[7832, 1000, 139, 976]\n"
          ]
        }
      ],
      "source": [
        "l= api.my_status() # Get my game stats: (# of tries, # of wins)\n",
        "success_rate = l[2]/l[1]\n",
        "print(l)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "FINAL RESULT ON 1000 results : 14%"
      ],
      "metadata": {
        "id": "ksPcD8tgtyDQ"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}